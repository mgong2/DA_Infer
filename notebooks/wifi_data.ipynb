{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process wifi dataset\n",
    "Consider t1, t2, t3 three domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from os.path import join\n",
    "import numpy as np\n",
    "np.set_printoptions(linewidth=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create .npz data by random subsampling 10 subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract data\n",
    "target_id = 3\n",
    "num_train = 700\n",
    "num_domain = 3\n",
    "data_path = join('../data/wifi/', 'aligned_data.mat')\n",
    "data_wifi = loadmat(data_path)\n",
    "x_t1 = data_wifi['X1_new']\n",
    "y_t1 = data_wifi['Y1_new']\n",
    "x_t2 = data_wifi['X2_new']\n",
    "y_t2 = data_wifi['Y2_new']\n",
    "x_t3 = data_wifi['X3_new']\n",
    "y_t3 = data_wifi['Y3_new']\n",
    "ss1 = x_t1.shape[0]\n",
    "ss2 = x_t2.shape[0]\n",
    "ss3 = x_t3.shape[0]\n",
    "x = np.concatenate((x_t1, x_t2, x_t3), 0)\n",
    "y = np.concatenate((y_t1, y_t2, y_t3), 0)\n",
    "if target_id == 3:\n",
    "    label_d = np.concatenate((np.ones((ss1, 1))*0, np.ones((ss2, 1))*1, np.ones((ss3, 1))*2))\n",
    "elif target_id == 2:\n",
    "    label_d = np.concatenate((np.ones((ss1, 1))*0, np.ones((ss2, 1))*2, np.ones((ss3, 1))*1))\n",
    "else:\n",
    "    label_d = np.concatenate((np.ones((ss1, 1))*2, np.ones((ss2, 1))*0, np.ones((ss3, 1))*1))\n",
    "\n",
    "y = np.concatenate((y, label_d), 1)\n",
    "\n",
    "# extract Markov Blanket\n",
    "# MB = dag_mat['MB'].flatten() - 1\n",
    "# x = x[:, MB[:-2]]\n",
    "\n",
    "# random subsamspling\n",
    "for seed in range(1, 11):\n",
    "    full_path = join('../data/wifi/', 'tot%d_dataId%d.npz'%(target_id, seed))\n",
    "    np.random.seed(seed)\n",
    "    total_num_samples = y.shape[0]\n",
    "    indices = np.arange(total_num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    x_sub = x[indices[0:num_train*num_domain]]\n",
    "    y_sub = y[indices[0:num_train*num_domain]]\n",
    "    # save data\n",
    "    np.savez(full_path, x=x_sub, y=y_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert .npz to .mat format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataId in range(1, 11):\n",
    "    for targetId in range(1, 4):\n",
    "        file_path = '../data/wifi/tot%d_dataId%d.npz' % (targetId, dataId)\n",
    "        file_path_mat = '../data/wifi/tot%d_dataId%d.mat' % (targetId, dataId)\n",
    "        npzfile = np.load(file_path)\n",
    "        list(npzfile.keys())\n",
    "        savemat(file_path_mat, mdict={'x':npzfile['x'],'y':npzfile['y']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create python data_mat and Markov Blanket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 18)\n"
     ]
    }
   ],
   "source": [
    "dag_mat_file = '../data/wifi/t1t3_dag.mat'\n",
    "dag_wifi = loadmat(dag_mat_file)\n",
    "dag_mat = dag_wifi['gn']\n",
    "MB = dag_wifi['MB'].flatten() - 1\n",
    "dag_mat = dag_mat.T\n",
    "# extract MB in the DAG if using MB data\n",
    "dag_mat = dag_mat[np.ix_(MB[:-2], MB)]\n",
    "print(dag_mat.shape)\n",
    "full_path = '../data/wifi/t1t3_dag.npz'\n",
    "np.savez(full_path, mat=dag_mat, MB=MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19,)\n"
     ]
    }
   ],
   "source": [
    "data_path = join('../data/wifi/', 'aligned_data.mat')\n",
    "data = loadmat(data_path)\n",
    "y = data['Y1_new']\n",
    "unique_y = np.unique(y)\n",
    "print(unique_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7 10 11 12 13 14 43 15 19 67 68]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 18)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = join('../data/wifi/', 't1t2_dag.mat')\n",
    "data = loadmat(data_path)\n",
    "MB = data['MB'].flatten()-1\n",
    "print(MB)\n",
    "dag_mat = data['gn'].T\n",
    "# data['gn'][np.ix_(MB, MB)].T\n",
    "dag_mat[np.ix_(MB[:-2], MB)].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = join('../data/wifi/', 't2t3_dag.mat')\n",
    "data = loadmat(data_path)\n",
    "data['MB'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = join('../data/wifi/', 't1t3_dag.mat')\n",
    "data = loadmat(data_path)\n",
    "data['MB'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100, 17)\n",
      "(2100, 2)\n"
     ]
    }
   ],
   "source": [
    "npzfile = np.load('../data/wifi/tot1_dataId1.npz')\n",
    "print(npzfile['x'].shape)\n",
    "print(npzfile['y'].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
